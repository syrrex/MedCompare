{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfMJiPIJciiE"
      },
      "source": [
        "# MedCompare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNsSg8YKfMzp"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "Attention: before running, switch to gpu execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RrF0ZPB1Exvv",
        "outputId": "d15dfcd8-ad83-4a49-fd56-a4b760b20bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UIkulk82e5Bl"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "daa6edc934504a61925f9d047f65b80f",
            "c1ac4d41c69f4824956e6a8507a115f0",
            "12f8c8772fe540bd9cdcf0dca3990ad2",
            "efac1070a27f4b95a9bed223a916a756",
            "2862ac637bb54c528656b84fad9a8b41",
            "202e9c763a8c4033a93e142049ac879d",
            "c5025ea82d644dab835126fc866c4932",
            "22fe00da79b34e018aabd4c0ada33847",
            "2b559a23512042a987bca8a58879f0e2",
            "f6f28282e68448b6bf675c9adb740595",
            "2995defb86084d578d04aaa381343e34",
            "23d5dba89f29487a923e8ef77f8c50f0",
            "01e7c99093084bd3ad117bef6024ec12",
            "b65b72202b3c42729d5867c7dd243dd6",
            "a0a76c2c6056498e9c2a73a9919d32a2",
            "b20a2852deb044abad3813c01576b0a9",
            "1e04d148b1d44019a4351d37d7b13998",
            "0154bf1cdb744d4f920428f2d93c6251",
            "07503ecf8ac3440ca20c5913a0e867ff",
            "8b0186df75ae43319853382802915d1f"
          ]
        },
        "id": "WrW1gbjUfINm",
        "outputId": "5f0eb9f7-383b-40a1-b870-8406c6551f53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daa6edc934504a61925f9d047f65b80f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMQauq56dFPs"
      },
      "source": [
        "## 1. Data Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KEvcPyde7dpU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, pipeline, AutoModel, pipeline\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQW_T8HM70Ag"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "D5yMjJEq7q1f"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"MattBastar/Medicine_Details\")\n",
        "data = dataset['train']\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TacPl2j78BYZ"
      },
      "source": [
        "We get the ontology mapping via open source platform BioPortal bioontology. For this u need a file (api-key.txt) that contains an api-key for BioPortal. For this create an account5 at https://bioportal.bioontology.org/ and get your own key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "awP04anTLUfN"
      },
      "outputs": [],
      "source": [
        "# Function to clean text\n",
        "\n",
        "# def clean_text(text):\n",
        "#     text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
        "#     text = re.sub(r\"\\b\\d+\\b\", \"\", text)  # Remove standalone numbers\n",
        "#     text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "#     return text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Step 1: Remove special characters except for alphanumeric and spaces\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Keep only letters and spaces\n",
        "\n",
        "    # Step 2: Remove standalone numbers\n",
        "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)\n",
        "\n",
        "    # Step 3: Remove specific unwanted terms\n",
        "    unwanted_terms = [\"mg\", \"treatment\", \"Treatment\", \"MG\", \"mg\", \"ML\", \"ml\", \"of\", \"mgml\"]  # Add other terms to this list as needed\n",
        "    for term in unwanted_terms:\n",
        "        text = re.sub(rf\"\\b{term}\\b\", \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Step 4: Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3q0ReevGGO56"
      },
      "outputs": [],
      "source": [
        "# #BASE_URL = \"http://data.bioontology.org\"\n",
        "# #file = open(\"api-key.txt\", \"r\")\n",
        "# API_KEY = file.read().strip()\n",
        "# #file.close()\n",
        "\n",
        "# headers = {\n",
        "#     \"Authorization\": f\"apikey token={API_KEY}\"\n",
        "# }\n",
        "\n",
        "# Function to look up ontology mappings from BioPortal API\n",
        "\n",
        "# def get_bioportal_mapping(term):\n",
        "\n",
        "#     params = {\n",
        "#         \"q\": term,\n",
        "#         \"require_exact_match\": \"false\" # false or true  deoending on exact matching\n",
        "#     }\n",
        "#     response = requests.get(f\"{BASE_URL}/search\", headers=headers, params=params)\n",
        "\n",
        "#     if response.status_code != 200:\n",
        "#         return {term: \"unknown\"}  # Default to \"unknown\" if the API call fails\n",
        "\n",
        "#     data = response.json()\n",
        "\n",
        "#     # Filter relevant mappings based on ontology prefixes else words without medical context get mapped as well\n",
        "#     relevant_prefixes = [\n",
        "#         \"http://purl.bioontology.org/ontology\",  # BioPortal's main prefix\n",
        "#         \"http://www.co-ode.org/ontologies/galen\",  # GALEN ontology\n",
        "#         \"http://ncicb.nci.nih.gov\"  # NCI Thesaurus\n",
        "#     ]\n",
        "\n",
        "#     for result in data.get(\"collection\", []):\n",
        "#         label = result.get(\"prefLabel\")\n",
        "#         ontology_id = result.get(\"@id\")\n",
        "\n",
        "#         if label and ontology_id and any(ontology_id.startswith(prefix) for prefix in relevant_prefixes):\n",
        "#             return {label.lower(): ontology_id}\n",
        "\n",
        "#     # Default\n",
        "#     return {term: \"unknown\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NJHr2VcBJgN"
      },
      "source": [
        "### Processing User Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBdGcnFni46x",
        "outputId": "874f86ec-453e-4d4c-f5b0-bae55a675c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\"token-classification\", model=\"Clinical-AI-Apollo/Medical-NER\", aggregation_strategy=\"simple\")\n",
        "\n",
        "def preprocess_user_input_with_ner(user_input):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Step 1: Use the NER pipeline to extract medical entities\n",
        "    ner_results = pipe(user_input)\n",
        "\n",
        "    # Step 2: Group all entities by their types\n",
        "    grouped_entities = {}\n",
        "    for entity in ner_results:\n",
        "        entity_group = entity[\"entity_group\"]\n",
        "        if entity_group not in grouped_entities:\n",
        "            grouped_entities[entity_group] = []\n",
        "        grouped_entities[entity_group].append(entity[\"word\"])\n",
        "\n",
        "    # Step 3: Collect all identified words\n",
        "    all_words = []\n",
        "    for group, words in grouped_entities.items():\n",
        "        all_words.extend(words)\n",
        "\n",
        "    # Step 4: Combine all words into a single string\n",
        "    combined_text = \" \".join(all_words)\n",
        "    print(f\"Combined Text: {combined_text}\")\n",
        "\n",
        "    # Step 5: Generate a single embedding for the combined text\n",
        "    inputs = tokenizer(combined_text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        combined_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # CLS token embedding\n",
        "\n",
        "    # Step 6: Return results\n",
        "    return {\n",
        "        \"cleaned_input\": user_input,\n",
        "        \"ner_results\": ner_results,\n",
        "        \"grouped_entities\": grouped_entities,\n",
        "        \"all_words\": all_words,\n",
        "        \"combined_text\": combined_text,\n",
        "        \"combined_embedding\": combined_embedding  # Single combined embedding\n",
        "    }\n",
        "\n",
        "def preprocess_user_input_with_ner_tfidf(user_input):\n",
        "    # Step 1: Use the NER pipeline to extract medical entities\n",
        "    ner_results = pipe(user_input)\n",
        "\n",
        "    # Step 2: Group all entities by their types\n",
        "    grouped_entities = {}\n",
        "    for entity in ner_results:\n",
        "        entity_group = entity[\"entity_group\"]\n",
        "        if entity_group not in grouped_entities:\n",
        "            grouped_entities[entity_group] = []\n",
        "        grouped_entities[entity_group].append(entity[\"word\"])\n",
        "\n",
        "    # Step 3: Collect all identified words\n",
        "    all_words = []\n",
        "    for group, words in grouped_entities.items():\n",
        "        all_words.extend(words)\n",
        "\n",
        "    # Step 4: Combine all words into a single string\n",
        "    combined_text = \" \".join(all_words)\n",
        "    print(f\"Combined Text: {combined_text}\")\n",
        "\n",
        "    tfidf_embeddings = vectorizer.transform([combined_text])\n",
        "\n",
        "    print(tfidf_embeddings.shape)\n",
        "    # Step 6: Return results\n",
        "    return {\n",
        "        \"cleaned_input\": user_input,\n",
        "        \"ner_results\": ner_results,\n",
        "        \"grouped_entities\": grouped_entities,\n",
        "        \"all_words\": all_words,\n",
        "        \"combined_text\": combined_text,\n",
        "        \"combined_embedding\": tfidf_embeddings  # Feature names for interpretation\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vxVS53glSo1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing for User Input aswell as Dataset"
      ],
      "metadata": {
        "id": "MrF0a6l3uKWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "UzTzfFWgQSGM"
      },
      "outputs": [],
      "source": [
        "def preprocess_with_ner(text_input):\n",
        "    ner_results = pipe(text_input)\n",
        "    all_words = [entity[\"word\"] for entity in ner_results]\n",
        "    combined_text = \" \".join(all_words)\n",
        "    return combined_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OrSEJOcpQvt6",
        "outputId": "e26f0a65-b0ef-4de6-9a2f-81fbef2a0651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing records:   0%|          | 0/11825 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Processing records:   8%|▊         | 928/11825 [00:27<04:34, 39.72it/s]"
          ]
        }
      ],
      "source": [
        "def combine_text(record):\n",
        "    composition = clean_text(record['Composition'])\n",
        "    uses = clean_text(record['Uses'])\n",
        "    return f\"{composition}{uses}\"\n",
        "\n",
        "\n",
        "processed_texts = [preprocess_with_ner(combine_text(record)) for record in tqdm(data, desc=\"Processing records\")]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtT6nk5KmHkf"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "output_file = \"processed_texts.csv\"\n",
        "\n",
        "# Save to a CSV file\n",
        "with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Processed Text\"])  # Header row\n",
        "    for text in processed_texts:\n",
        "        writer.writerow([text])\n",
        "\n",
        "print(f\"Processed texts saved to {output_file}\")\n",
        "from google.colab import files\n",
        "\n",
        "# Download the CSV file\n",
        "files.download(output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and store Dataset embeddings with Clinical-BERT"
      ],
      "metadata": {
        "id": "knYi-Hs5rX-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO0ruTa7jv7P"
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(processed_text, model, tokenizer):\n",
        "  print(\"Executing with Cuda GPU: \" + str(torch.cuda.is_available()))\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "  embeddings = []\n",
        "  for text in tqdm(processed_text, desc=\"Generating embeddings\"):\n",
        "      inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "      embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
        "      embeddings.append(embedding)\n",
        "\n",
        "  # Convert embeddings to a NumPy array\n",
        "  entity_embedding = np.array(embeddings)\n",
        "  return entity_embedding\n",
        "\n",
        "\n",
        "data_embeddings_bert = generate_embeddings(processed_texts, model, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLK2_Nh7x3xs"
      },
      "outputs": [],
      "source": [
        "embeddings_file = \"data_embeddings_bert.npy\"\n",
        "np.save(embeddings_file, data_embeddings_bert)\n",
        "\n",
        "print(f\"BERT Embeddings saved to {embeddings_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and store Dataset embeddings with TFIDF"
      ],
      "metadata": {
        "id": "TA-sCA2aqUCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tfidf_embeddings(processed_texts):\n",
        "    processed_texts = [text for text in processed_texts if text.strip()]\n",
        "\n",
        "    tfidf_embeddings = vectorizer.fit_transform(processed_texts)\n",
        "\n",
        "    return tfidf_embeddings\n",
        "\n",
        "\n",
        "data_embeddings_tfidf = generate_tfidf_embeddings(processed_texts)\n"
      ],
      "metadata": {
        "id": "cPJK3IygqRaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_file = \"data_embeddings_tfidf.npy\"\n",
        "np.save(embeddings_file, data_embeddings_tfidf)\n",
        "\n",
        "print(f\"TFIDF Embeddings saved to {embeddings_file}\")\n"
      ],
      "metadata": {
        "id": "0uW8RAeDssym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCNJeO7cddMH"
      },
      "source": [
        "## 2. Similarity Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data Embeddings and Query Embeddings for Ranking\n",
        "\n",
        "TODO: maybe add normalization before embedding"
      ],
      "metadata": {
        "id": "V2reNuJvAncd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "eP62swTlFhPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function for user query preprocessing"
      ],
      "metadata": {
        "id": "HmQzQSZSfWMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_query_for_similarity_ranking(query, embedding_type = 'bert'):\n",
        "\n",
        "  query = clean_text(query)\n",
        "\n",
        "  if(embedding_type == 'tfidf'):\n",
        "    preprocessed_query = preprocess_user_input_with_ner_tfidf(query)\n",
        "  else:\n",
        "    preprocessed_query = preprocess_user_input_with_ner(query)\n",
        "\n",
        "  print(\"NER Results:\", preprocessed_query[\"ner_results\"])\n",
        "  print(f\"NER Query for Embedding: {preprocessed_query['combined_text']}\")\n",
        "\n",
        "  query_embedding = preprocessed_query[\"combined_embedding\"]\n",
        "\n",
        "  # print(group_embedding.shape)\n",
        "  # print(embedding_type)\n",
        "  if(embedding_type == 'bert'):\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
        "\n",
        "  return query_embedding\n"
      ],
      "metadata": {
        "id": "1cw_gkYlA6WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function for ranking best Matches and Eliminate Duplicates, because necessary only Substances and Dataset provides multiple solutions with different dosages\n"
      ],
      "metadata": {
        "id": "5EQjuWnHfLsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_ranking(similarities, data, top_k = 5):\n",
        "\n",
        "  medicine_names = [record['Medicine Name'] for record in data]\n",
        "  compositions = [record['Composition'] for record in data]\n",
        "  uses= [record['Uses'] for record in data]\n",
        "  side_effects = [record['Side_effects'] for record in data]\n",
        "  ratings = [record['Average Review %'] for record in data]\n",
        "\n",
        "\n",
        "  ranked_indices = np.argsort(similarities[0])[::-1]  # Sort indices by similarity in descending order\n",
        "\n",
        "  unique_compositions = set()\n",
        "  final_results = []  # To store the final unique top-k results\n",
        "\n",
        "  for idx in ranked_indices:\n",
        "      medicine_name = medicine_names[idx]\n",
        "      composition = compositions[idx]\n",
        "      use = uses[idx]\n",
        "      side_effect = side_effects[idx]\n",
        "      average_review = ratings[idx]\n",
        "\n",
        "      # Check for uniqueness based on composition\n",
        "      if clean_text(composition) not in unique_compositions:\n",
        "          unique_compositions.add(clean_text(composition)) # Mark composition as seen\n",
        "          final_results.append({\n",
        "              \"Medicine\": medicine_name,\n",
        "              \"Composition\": composition,\n",
        "              \"Use\": use,\n",
        "              \"Side Effects\": side_effect,\n",
        "              \"Similarity\": similarities[0][idx]\n",
        "          })\n",
        "\n",
        "      if len(final_results) == top_k:\n",
        "          break\n",
        "  return final_results"
      ],
      "metadata": {
        "id": "oJn1FDG4eQWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function for printing top results"
      ],
      "metadata": {
        "id": "h3_0ndktel-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(similarity_results):\n",
        "  print(\"\\nTop matching medications with side effects:\")\n",
        "  for result in similarity_results:\n",
        "      print(f\"Medicine: {result['Medicine']},\\nComposition: {result['Composition']}, Use: {result['Use']}, \\nSide Effects: {result['Side Effects']},\\n Similarity: {result['Similarity']:.4f}\\n\")\n",
        "\n",
        "  print(\"\\n\" + \"=\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "id": "EciB9CGzeZ9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculating Cosine Similarities with Sklearn\n",
        "and combine all together"
      ],
      "metadata": {
        "id": "K7msraRHAa8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(query, data_embedding, ground_data, embedding_type = 'bert'):\n",
        "    query_embedding = prepare_query_for_similarity_ranking(query, embedding_type)\n",
        "    #cosine similarity sklearn\n",
        "    similarities = cosine_similarity(query_embedding, data_embedding)\n",
        "    similarity_results = similarity_ranking(similarities, ground_data)\n",
        "    print_results(similarity_results)\n"
      ],
      "metadata": {
        "id": "69XzyWpBAPfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing of Similarity Ranking"
      ],
      "metadata": {
        "id": "Vv-P5S3RChc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"acute migraine\"\n",
        "similarity(query, data_embeddings_tfidf, data, embedding_type = 'tfidf')\n",
        "similarity(query, data_embeddings_bert, data)"
      ],
      "metadata": {
        "id": "wuGs31QsE77l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluation of Clinical-BERT & TFIDF results\n"
      ],
      "metadata": {
        "id": "mDBR-HoduyNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Query Dictonary with evaluation:\n",
        "rating_precision -> bool relevant or not\n",
        "rating_relevance -> output top 5 (1,2,3,4,5) gets a relevant rating like following:\n",
        "5: Highly relevant (most relevant item to the query).\n",
        "4: Very relevant (still strongly related to the query).\n",
        "3: Moderately relevant (somewhat useful for the query).\n",
        "2: Slightly relevant (not very useful but loosely related).\n",
        "1: Not relevant (unlikely to satisfy the query)."
      ],
      "metadata": {
        "id": "9QlkxZzOaR35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rr9Rt-GJ5C1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'tfidf'\n",
        "query = query\n",
        "rating_precision_tfidf = (0, 0, 0, 1, 1)\n",
        "rating_precision_bert = (1, 1, 1, 0, 1)\n",
        "relevance_rating_tfidf = (0, 0, 0, 3, 3)\n",
        "relevance_rating_bert = (5, 5, 5, 0, 5)\n",
        "model_rating_tfidf = {'query': query, 'rating_prec': rating_precision_tfidf, 'sum_relevant_items': 14, 'relevance_rating': relevance_rating_tfidf}\n",
        "model_rating_bert = {'query': query, 'rating_prec': rating_precision_bert, 'sum_relevant_items': 14, 'relevance_rating': relevance_rating_bert}"
      ],
      "metadata": {
        "id": "12og1yK2aRAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Precision@K and Recall@K"
      ],
      "metadata": {
        "id": "Iz42HU5MTJCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\n",
        "\\text{Precision@K} = \\frac{\\text{Number of relevant items in top-K}}{K}\n",
        "$\n"
      ],
      "metadata": {
        "id": "UL3fkiH8URMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(model_rating):\n",
        "    #model_rating['query']\n",
        "    relevant_in_top_k = sum(model_rating['rating_prec'])\n",
        "    return relevant_in_top_k / 5\n",
        "\n",
        "value_tfidf = precision(model_rating_tfidf)\n",
        "value_bert = precision(model_rating_bert)\n",
        "print(\"precision values:\")\n",
        "print(f'TFIDF: {value_tfidf}')\n",
        "print(f'BERT: {value_bert}')"
      ],
      "metadata": {
        "id": "AlX2NzVOVSe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Recall@K} = \\frac{\\text{Number of relevant items in top-K}}{\\text{Total number of relevant items}}$"
      ],
      "metadata": {
        "id": "0M6QIP6rWE5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(model_rating):\n",
        "    relevant_in_top_k = sum(model_rating['rating_prec'])\n",
        "    return relevant_in_top_k / model_rating['sum_relevant_items']\n",
        "\n",
        "value_tfidf = recall(model_rating_tfidf)\n",
        "value_bert = recall(model_rating_bert)\n",
        "print(\"recall values:\")\n",
        "print(f'TFIDF: {value_tfidf}')\n",
        "print(f'BERT: {value_bert}')"
      ],
      "metadata": {
        "id": "1pj7pCWbWEl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NDCG Normalized discounted cumulative gain"
      ],
      "metadata": {
        "id": "kbG8pVXQWarW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{IDCG@K} = \\sum_{i=1}^{K} \\frac{\\text{ideal relevance}_i}{\\log_2(i + 1)}$\n",
        "\n",
        "$\\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}}$"
      ],
      "metadata": {
        "id": "59HRQYeYWQPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg(model_rating):\n",
        "    dcg = 0.0\n",
        "    idcg = 0.0\n",
        "    relevance_scores = model_rating['relevance_rating']\n",
        "    for i, score in enumerate(relevance_scores):\n",
        "        dcg += score / np.log2(i + 2)\n",
        "\n",
        "    ideal_scores = sorted(relevance_scores, reverse=True)\n",
        "    for i, score in enumerate(ideal_scores):\n",
        "        idcg += score / np.log2(i + 2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "value_tfidf = ndcg(model_rating_tfidf)\n",
        "value_bert = ndcg(model_rating_bert)\n",
        "print(\"recall values:\")\n",
        "print(f'TFIDF: {value_tfidf}')\n",
        "print(f'BERT: {value_bert}')"
      ],
      "metadata": {
        "id": "q55mjLq9WQAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compare Models\n",
        "Plotting etc for certain querys"
      ],
      "metadata": {
        "id": "XdRRkph2XRAn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IvdlrRsLXab7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "daa6edc934504a61925f9d047f65b80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_c5025ea82d644dab835126fc866c4932"
          }
        },
        "c1ac4d41c69f4824956e6a8507a115f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fe00da79b34e018aabd4c0ada33847",
            "placeholder": "​",
            "style": "IPY_MODEL_2b559a23512042a987bca8a58879f0e2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "12f8c8772fe540bd9cdcf0dca3990ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f6f28282e68448b6bf675c9adb740595",
            "placeholder": "​",
            "style": "IPY_MODEL_2995defb86084d578d04aaa381343e34",
            "value": ""
          }
        },
        "efac1070a27f4b95a9bed223a916a756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_23d5dba89f29487a923e8ef77f8c50f0",
            "style": "IPY_MODEL_01e7c99093084bd3ad117bef6024ec12",
            "value": false
          }
        },
        "2862ac637bb54c528656b84fad9a8b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b65b72202b3c42729d5867c7dd243dd6",
            "style": "IPY_MODEL_a0a76c2c6056498e9c2a73a9919d32a2",
            "tooltip": ""
          }
        },
        "202e9c763a8c4033a93e142049ac879d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b20a2852deb044abad3813c01576b0a9",
            "placeholder": "​",
            "style": "IPY_MODEL_1e04d148b1d44019a4351d37d7b13998",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c5025ea82d644dab835126fc866c4932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "22fe00da79b34e018aabd4c0ada33847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b559a23512042a987bca8a58879f0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6f28282e68448b6bf675c9adb740595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2995defb86084d578d04aaa381343e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d5dba89f29487a923e8ef77f8c50f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e7c99093084bd3ad117bef6024ec12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65b72202b3c42729d5867c7dd243dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a76c2c6056498e9c2a73a9919d32a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b20a2852deb044abad3813c01576b0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e04d148b1d44019a4351d37d7b13998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0154bf1cdb744d4f920428f2d93c6251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07503ecf8ac3440ca20c5913a0e867ff",
            "placeholder": "​",
            "style": "IPY_MODEL_8b0186df75ae43319853382802915d1f",
            "value": "Connecting..."
          }
        },
        "07503ecf8ac3440ca20c5913a0e867ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0186df75ae43319853382802915d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}